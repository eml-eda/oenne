{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "LI4-dGlWtHMM",
   "metadata": {
    "id": "LI4-dGlWtHMM"
   },
   "source": [
    "**TODO**: Remove below (drive-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0GNlwGsfPe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa0GNlwGsfPe",
    "outputId": "a80b7116-3886-498a-ea8b-13150affcfa0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#!ln -s /content/drive/MyDrive/Didattica/OENNE_notebooks/utils ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a35c97-8b34-4c38-a930-3d709420609f",
   "metadata": {},
   "source": [
    "**TODO**: Remove below (server-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06f6deb-a721-4836-8b00-a329f2ba9906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f978ca1",
   "metadata": {
    "id": "0f978ca1"
   },
   "source": [
    "## Hands-on #3: Quantization with PLiNIO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c2bcfe",
   "metadata": {
    "id": "59c2bcfe"
   },
   "source": [
    "In this notebook, you will:\n",
    "1. Load the optimized and pruned DNN found at the end of Hands-on #2\n",
    "2. Apply Quantization-Aware Training (QAT) to it.\n",
    "3. Export the final model in an ONNX format compatible with the AI Compiler that you will use in Hands-on #4.\n",
    "\n",
    "Considering the flow seen in class, we are here:\n",
    "\n",
    "![qat.png]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3da17-365b-4f04-86ac-a6dd0b7aac90",
   "metadata": {
    "id": "fcf3da17-365b-4f04-86ac-a6dd0b7aac90"
   },
   "source": [
    "# Part 0: Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d8e445-aa06-43d3-8ad9-059be3da58c3",
   "metadata": {
    "id": "58d8e445-aa06-43d3-8ad9-059be3da58c3"
   },
   "source": [
    "As usual, we start by importing required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a45bae-11ce-4318-9386-f74cb68ca0f0",
   "metadata": {
    "id": "a4a45bae-11ce-4318-9386-f74cb68ca0f0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from plinio.cost import params_bit\n",
    "from plinio.methods import MPS\n",
    "from plinio.methods.mps import get_default_qinfo\n",
    "from plinio.methods.mps.quant.quantizers import PACTAct\n",
    "from plinio.methods.mps.quant.backends import Backend, integerize_arch\n",
    "from plinio.methods.mps.quant.backends.match import MATCHExporter\n",
    "\n",
    "import pytorch_benchmarks.image_classification as icl\n",
    "from pytorch_benchmarks.utils import CheckPoint, EarlyStopping\n",
    "\n",
    "from utils.train import set_seed, try_load_checkpoint\n",
    "from utils.plot import plot_learning_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b9e0f1-3de5-4840-ab8a-d89176a4bd74",
   "metadata": {
    "id": "f2b9e0f1-3de5-4840-ab8a-d89176a4bd74"
   },
   "source": [
    "And repeat the initial configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dddbd68-b3e8-4e35-a9c6-cfe0d12d6ade",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dddbd68-b3e8-4e35-a9c6-cfe0d12d6ade",
    "outputId": "57111746-8c05-4ced-dc9d-c4f2cad614fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = Path(f\"experiments/02/\")\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    'in_class': False,          # kept for compatibility with hands-on #1. Leave it as false!\n",
    "    'epochs': 50,               # max epochs for normal trainings\n",
    "    'nas_epochs': 100,          # max epochs for the NAS search loop\n",
    "    'nas_no_stop_epochs': 20,   # initial epochs without early stopping for the NAS\n",
    "    'batch_size': 32,           # batch size\n",
    "    'lr': 0.1,                  # initial learning rate for normal trainings\n",
    "    'search_lr_net': 0.001,     # learning rate for DNN weights during NAS\n",
    "    'search_lr_nas': 0.001,     # learning rate for NAS parameters during NAS\n",
    "    'weight_decay': 1e-4,       # weight decay for normal DNN parameters\n",
    "    'patience': 10,             # early-stopping patience for normal trainings\n",
    "    'nas_patience': 10,         # early-stopping patience for NAS search\n",
    "}\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Working on: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e410210-8a49-4d48-b0b2-e7061b1c96e4",
   "metadata": {
    "id": "4e410210-8a49-4d48-b0b2-e7061b1c96e4"
   },
   "source": [
    "# Part 1: Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c831a8e-e2b2-4c51-a4f5-ca12ac3ec5ef",
   "metadata": {
    "id": "3c831a8e-e2b2-4c51-a4f5-ca12ac3ec5ef"
   },
   "source": [
    "Dataset preparation is identical to the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b7f59f-1367-4417-9d1d-f100f61d1e8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1b7f59f-1367-4417-9d1d-f100f61d1e8f",
    "outputId": "328ed0a9-884b-4ff4-9d16-0357ba0a98d4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "datasets = icl.get_data()\n",
    "dataloaders = icl.build_dataloaders(datasets, batch_size=TRAINING_CONFIG['batch_size'])\n",
    "train_dl, val_dl, test_dl = dataloaders\n",
    "\n",
    "input_shape = datasets[0][0][0].numpy().shape\n",
    "batch_shape = (1,) + input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cFj-TvcpcS6",
   "metadata": {
    "id": "0cFj-TvcpcS6"
   },
   "source": [
    "# Part 2: Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q7rkOr7vwk9r",
   "metadata": {
    "id": "Q7rkOr7vwk9r"
   },
   "source": [
    "All DNN models considered up to now used **32-bit floating point** for internal operations, and for storing weights and activations. However, our hardware target only supports Quantized DNN inference, using **8-bit integers**. Therefore, we need to convert our model to that format before we can export it and compile it.\n",
    "\n",
    "Simply quantizing a model by replacing all floating point data with their closest integer approximation (the most basic form of Post-Training Quantization) could worsen its accuracy. Fortunately, this drop can often be recovered by running some epochs of the so-called **Quantization-Aware Training (QAT)**, as seen in class.\n",
    "\n",
    "PLiNIO an be used to perform QAT on our model, as well as allowing to export the final \"full integer\" model in a format compatible with the compiler used in one of the next sessions.  \n",
    "\n",
    "More precisely, PLiNIO's QAT function is embedded in the `MPS()` class, which is used to perform a more advanced optimization: **Mixed-Precision Search**. This optimization applies QAT at *multiple bit-widths* simultaneously, and uses a SuperNet-like method to select the *best precision assignment* for the weights and activations of different portions of a DNN (different layers, or even different channels of the same layer).\n",
    "The optimization can be driven by a two-terms loss function considering accuracy and cost, similar to the one used with SuperNet and PIT.\n",
    "\n",
    "We will not use MPS in this session, since our target hardware and backend library do not support $<8$ bit inference (*). However, we can still use PLiNIO to perform a simple QAT run, by simply reducing it to a **\"corner case\" of MPS, with a single precision** (8-bit) to select from.\n",
    "\n",
    "If you're interested in the details on the MPS algorithm present in PLiNIO, check-out these two papers: [link1](https://arxiv.org/abs/2206.08852), [link2](https://arxiv.org/abs/2004.05795). Feel free to also try applying MPS with multiple precisions on our DNN as an extra. Although we won't be able to deploy models with precisions different from 8-bit, it could still be interesting to check how much we can compress the weights without losing too much accuracy.\n",
    "\n",
    " \n",
    "(*) Actually, the DNN accelerator present in GAP9 would support those representations, but we will only deploy on the multi-core RISC-V cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f76fa7-0d04-4c96-bba6-34b16bb5c50f",
   "metadata": {},
   "source": [
    "## Importing the Model\n",
    "\n",
    "Let's start by loading the final model from Hands-on #2 (Optimized and Pruned):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96f8fad-09cb-4280-9c4c-e06a09ffa62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"./experiments/02/final_model.pt\")\n",
    "model = torch.load(MODEL_PATH).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a25cc-4f01-4619-bd7d-de87dae1c737",
   "metadata": {},
   "source": [
    "Quickly verify that it's correctly loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8637a9bb-73c7-4e4b-b468-c6802db13382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 50634, Test Loss: 1.9035611152648926, Test Acc: 28.84000015258789\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "test_metrics = icl.evaluate(model, criterion, test_dl, device)\n",
    "size = summary(model, batch_shape).total_params\n",
    "print(f'Size: {size}, Test Loss: {test_metrics[\"loss\"]}, Test Acc: {test_metrics[\"acc\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rp1zVH50-atb",
   "metadata": {
    "id": "rp1zVH50-atb"
   },
   "source": [
    "## Preparing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Fx2HOJgy-lBQ",
   "metadata": {
    "id": "Fx2HOJgy-lBQ"
   },
   "source": [
    "The constructor of the `MPS()` class in PLiNIO is similar to the one of PIT. The parameters are similar, and the conversion is mostly transparent. \n",
    "\n",
    "Note that we can ignore the `cost` parameter, if we're interested in just QAT. When running an actual MPS optimization on the DNN weights, you can for instance set this parameter to `params_bit`, a cost model that accounts for the precision (in bits) for each DNN parameter.\n",
    "\n",
    "The only key difference w.r.t. to other methods, is that `MPS` also expect a `qinfo` dictionary, containing settings on the desired type of quantization to apply for different parts of the network.\n",
    "\n",
    "The settings in `qinfo` include the quantization algorithm to use for weights and activations (e.g. min-max, PaCT, etc), and optional configuration parameters. In our case, it suffices to use the reasonable default settings provided by PLiNIO, by calling the `get_default_qinfo()` function. This function expects as input parameters the tuple of weights and activations bitwidths to be included in the optimization (in our case, only 8-bit for both).\n",
    "\n",
    "There's just one thing to customize in the default `qinfo`, namely the range of the DNN **input** quantizer. In fact, since we know that our (float) data is in the $[0, 1]$ range, we can set the initial range of the quantizer to be the same. This should facilitate the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "VImIBMbW-s32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "id": "VImIBMbW-s32",
    "outputId": "a1df1470-78b1-43cb-f65a-32073dc9558e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated DNN cost: 49418.0\n"
     ]
    }
   ],
   "source": [
    "# get the default qinfo dictionary, specifying 8-bit as the only precision for both weights and activations\n",
    "qinfo = get_default_qinfo((8,), (8,))\n",
    "\n",
    "# modify the default qinfo for the input layer, since we're using signed data in the [0, 1] range\n",
    "qinfo['input_default']['quantizer'] = PACTAct\n",
    "qinfo['input_default']['kwargs'] = {'init_clip_val': +1}\n",
    "\n",
    "# call the PLiNIO constructor\n",
    "mps_model = MPS(model, input_shape, qinfo=qinfo)\n",
    "mps_model = mps_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c6af7-1f40-4157-9d18-d91d64ca6721",
   "metadata": {},
   "source": [
    "### Looking at the Pruning Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094ecc1-eb9f-4334-9f64-9695f5c01963",
   "metadata": {},
   "source": [
    "Similarly to the SuperNet, we can look at the initial values of the PIT pruning masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2674479d-a358-4a30-993a-4f44fe6488ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for p in nas_model.nas_parameters(): \n",
    "        print((torch.abs(p)>0.5).int().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de89083-5e27-4eb7-a391-7bc4ffe20bec",
   "metadata": {},
   "source": [
    "**Question**: Is the number of mask values expected? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fHars-UFAqZR",
   "metadata": {
    "id": "fHars-UFAqZR"
   },
   "source": [
    "### Setting the Regularization Strength\n",
    "\n",
    "Identically to the SuperNet case, we have to set the value of $\\lambda$ for our combined loss function. Note that PIT generally requires *lower strength* values. However, as mentioned before, there isn't a golden rule here, unfortunately. Some trial and error is required (or a more advanced regulatization method such as [DUCCIO](https://ieeexplore.ieee.org/abstract/document/10278089). As a suggestion, try values $\\le 10^{-6}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "yMFvXHqNA5bg",
   "metadata": {
    "id": "yMFvXHqNA5bg"
   },
   "outputs": [],
   "source": [
    "TRAINING_CONFIG['reg_strength'] = 0 # (result around 83% acc - after fine-tuning, and 70k params - almost no pruning)\n",
    "#TRAINING_CONFIG['reg_strength'] = 1e-06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PI6CEP-PJdnO",
   "metadata": {
    "id": "PI6CEP-PJdnO"
   },
   "source": [
    "## Run the NAS Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Qb8qLFW8Bti7",
   "metadata": {
    "id": "Qb8qLFW8Bti7"
   },
   "source": [
    "For running the NAS optimization, we can reuse entirely the code seen in Hands-on #1. Thanks to the `ipynb` Python package, we can load definitions (classes, functions, etc) defined in another Jupyter notebook. Let's use it to load our NAS loop from Hands-on #1. Thanks to the transparent API of PLiNIO, this code, initially written for a SuperNet optimization, will work fine also for PIT. Clearly, to obtain optimal results, one would need to tweak with the parameters, which in some cases could require some code rewriting. However, for this basic example, reusing 100\\% of the NAS loop will suffice.\n",
    "\n",
    "The next cell runs the optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c53a25-ef0d-4a09-acea-ac2cac363458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 190.15batch/s, loss=1.68, acc=37.4, val_loss=1.56, val_acc=42.5]\n",
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 88.05batch/s, loss=1.56, acc=42.9, val_loss=1.55, val_acc=42.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 1 = 49418.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 186.96batch/s, loss=1.52, acc=44.3, val_loss=1.49, val_acc=46.1]\n",
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 89.14batch/s, loss=1.49, acc=45.7, val_loss=1.49, val_acc=46.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 2 = 49418.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 189.66batch/s, loss=1.44, acc=47.4, val_loss=1.42, val_acc=48]\n",
      "Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 87.90batch/s, loss=1.43, acc=48, val_loss=1.42, val_acc=48.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 3 = 49279.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 165.57batch/s, loss=1.39, acc=49.5, val_loss=1.41, val_acc=48.7]\n",
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 83.65batch/s, loss=1.42, acc=48, val_loss=1.46, val_acc=47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 4 = 48444.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 186.35batch/s, loss=1.36, acc=50.8, val_loss=1.37, val_acc=50.7]\n",
      "Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 84.92batch/s, loss=1.37, acc=51.3, val_loss=1.36, val_acc=51.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 5 = 48168.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 177.33batch/s, loss=1.33, acc=52.2, val_loss=1.31, val_acc=52.8]\n",
      "Epoch 6: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 70.48batch/s, loss=1.31, acc=52.5, val_loss=1.32, val_acc=52.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 6 = 48168.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 176.89batch/s, loss=1.29, acc=53.2, val_loss=1.28, val_acc=53.3]\n",
      "Epoch 7: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 75.02batch/s, loss=1.29, acc=53.8, val_loss=1.29, val_acc=53.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 7 = 48168.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|███████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 171.97batch/s, loss=1.27, acc=54.3, val_loss=1.27, val_acc=54]\n",
      "Epoch 8: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 76.92batch/s, loss=1.27, acc=54.9, val_loss=1.26, val_acc=54.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 8 = 47585.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 166.85batch/s, loss=1.25, acc=54.8, val_loss=1.27, val_acc=54.6]\n",
      "Epoch 9: 100%|████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 87.64batch/s, loss=1.3, acc=53, val_loss=1.3, val_acc=52.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 9 = 47189.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 169.49batch/s, loss=1.23, acc=56.1, val_loss=1.24, val_acc=55]\n",
      "Epoch 10: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 77.06batch/s, loss=1.27, acc=54.7, val_loss=1.9, val_acc=35.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 10 = 46707.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 175.05batch/s, loss=1.31, acc=53, val_loss=1.28, val_acc=54.1]\n",
      "Epoch 11: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 72.56batch/s, loss=1.38, acc=51.7, val_loss=1.29, val_acc=53.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 11 = 45471.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 180.54batch/s, loss=1.27, acc=54.8, val_loss=1.27, val_acc=54.9]\n",
      "Epoch 12: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 73.06batch/s, loss=1.27, acc=54.5, val_loss=1.26, val_acc=54.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 12 = 45607.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 186.60batch/s, loss=1.23, acc=55.8, val_loss=1.22, val_acc=56.3]\n",
      "Epoch 13: 100%|█████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 76.81batch/s, loss=1.25, acc=54.8, val_loss=1.26, val_acc=55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 13 = 45073.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 180.25batch/s, loss=1.22, acc=56.4, val_loss=1.25, val_acc=55.2]\n",
      "Epoch 14: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 82.21batch/s, loss=1.25, acc=55.1, val_loss=1.24, val_acc=55.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 14 = 44627.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 163.74batch/s, loss=1.19, acc=57.3, val_loss=1.2, val_acc=57.2]\n",
      "Epoch 15: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 88.66batch/s, loss=1.23, acc=56.2, val_loss=1.23, val_acc=56.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 15 = 44139.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 161.29batch/s, loss=1.18, acc=57.9, val_loss=1.22, val_acc=56.4]\n",
      "Epoch 16: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 83.50batch/s, loss=1.23, acc=56.5, val_loss=1.22, val_acc=56.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 16 = 43537.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 181.66batch/s, loss=1.17, acc=58.3, val_loss=1.18, val_acc=57.7]\n",
      "Epoch 17: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 71.11batch/s, loss=1.2, acc=56.6, val_loss=1.18, val_acc=57.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 17 = 43319.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 187.40batch/s, loss=1.16, acc=58.6, val_loss=1.22, val_acc=56.9]\n",
      "Epoch 18: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 92.50batch/s, loss=1.25, acc=55.4, val_loss=1.24, val_acc=55.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 18 = 42319.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|███████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 193.04batch/s, loss=1.16, acc=58.4, val_loss=1.2, val_acc=57]\n",
      "Epoch 19: 100%|█████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 81.28batch/s, loss=1.22, acc=56.9, val_loss=1.24, val_acc=56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 19 = 42163.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 184.12batch/s, loss=1.15, acc=58.9, val_loss=1.19, val_acc=58.1]\n",
      "Epoch 20: 100%|█████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 90.95batch/s, loss=1.18, acc=58, val_loss=1.18, val_acc=57.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 20 = 41150.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 194.99batch/s, loss=1.14, acc=59.6, val_loss=1.15, val_acc=58.9]\n",
      "Epoch 21: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 90.37batch/s, loss=1.2, acc=57.6, val_loss=1.16, val_acc=58.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 21 = 40679.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 193.69batch/s, loss=1.12, acc=60.1, val_loss=1.17, val_acc=58.6]\n",
      "Epoch 22: 100%|██████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 77.11batch/s, loss=1.32, acc=52.9, val_loss=1.2, val_acc=57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 22 = 40253.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 192.81batch/s, loss=1.12, acc=59.9, val_loss=1.16, val_acc=58.8]\n",
      "Epoch 23: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 88.12batch/s, loss=1.4, acc=49.8, val_loss=1.55, val_acc=44.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 23 = 39183.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 185.16batch/s, loss=1.18, acc=57.8, val_loss=1.15, val_acc=58.9]\n",
      "Epoch 24: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 77.43batch/s, loss=1.14, acc=59.2, val_loss=1.15, val_acc=59.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 24 = 38933.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 199.29batch/s, loss=1.12, acc=59.7, val_loss=1.14, val_acc=58.9]\n",
      "Epoch 25: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 86.42batch/s, loss=1.15, acc=58.9, val_loss=1.13, val_acc=59.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 25 = 38847.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 178.60batch/s, loss=1.11, acc=60.2, val_loss=1.16, val_acc=59.1]\n",
      "Epoch 26: 100%|█████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 92.77batch/s, loss=1.15, acc=59.7, val_loss=1.17, val_acc=58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 26 = 37898.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 187.56batch/s, loss=1.12, acc=60.1, val_loss=1.13, val_acc=59.8]\n",
      "Epoch 27: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 75.83batch/s, loss=1.15, acc=58.8, val_loss=1.13, val_acc=59.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 27 = 36999.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 199.01batch/s, loss=1.1, acc=60.9, val_loss=1.13, val_acc=59.2]\n",
      "Epoch 28: 100%|█████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 90.92batch/s, loss=1.16, acc=58.6, val_loss=1.17, val_acc=58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 28 = 36795.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 198.73batch/s, loss=1.12, acc=60, val_loss=1.15, val_acc=58.8]\n",
      "Epoch 29: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 83.00batch/s, loss=1.14, acc=59.5, val_loss=1.13, val_acc=59.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 29 = 36040.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 187.59batch/s, loss=1.1, acc=60.8, val_loss=1.13, val_acc=59.3]\n",
      "Epoch 30: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 89.50batch/s, loss=1.14, acc=59.5, val_loss=1.13, val_acc=59.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 30 = 35884.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 198.53batch/s, loss=1.08, acc=61.2, val_loss=1.12, val_acc=60.2]\n",
      "Epoch 31: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 92.54batch/s, loss=1.13, acc=59.7, val_loss=1.13, val_acc=59.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 31 = 34863.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 185.49batch/s, loss=1.09, acc=61, val_loss=1.11, val_acc=61]\n",
      "Epoch 32: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 77.93batch/s, loss=1.11, acc=59.8, val_loss=1.12, val_acc=59.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 32 = 34863.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 190.75batch/s, loss=1.08, acc=61.4, val_loss=1.1, val_acc=61.2]\n",
      "Epoch 33: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 80.07batch/s, loss=1.21, acc=57.8, val_loss=1.22, val_acc=57.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 33 = 34392.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 185.00batch/s, loss=1.09, acc=61.1, val_loss=1.11, val_acc=60.7]\n",
      "Epoch 34: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 84.90batch/s, loss=1.11, acc=60.5, val_loss=1.09, val_acc=60.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 34 = 33295.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 166.81batch/s, loss=1.08, acc=61.7, val_loss=1.13, val_acc=59.4]\n",
      "Epoch 35: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 90.32batch/s, loss=1.12, acc=60.6, val_loss=1.13, val_acc=60.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 35 = 32892.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 168.51batch/s, loss=1.07, acc=61.7, val_loss=1.12, val_acc=59.8]\n",
      "Epoch 36: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 89.68batch/s, loss=1.11, acc=60.6, val_loss=1.11, val_acc=60.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 36 = 32503.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 171.20batch/s, loss=1.07, acc=61.8, val_loss=1.09, val_acc=61]\n",
      "Epoch 37: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 85.15batch/s, loss=1.09, acc=60.8, val_loss=1.1, val_acc=60.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 37 = 31967.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|█████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 198.29batch/s, loss=1.07, acc=61.8, val_loss=1.1, val_acc=60.8]\n",
      "Epoch 38: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:04<00:00, 78.03batch/s, loss=1.09, acc=61.2, val_loss=1.09, val_acc=61.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 38 = 31853.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|███████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 180.67batch/s, loss=1.06, acc=62, val_loss=1.1, val_acc=61.3]\n",
      "Epoch 39: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 87.21batch/s, loss=1.11, acc=60.5, val_loss=1.09, val_acc=60.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 39 = 31219.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 184.36batch/s, loss=1.06, acc=62.4, val_loss=1.08, val_acc=61.9]\n",
      "Epoch 40: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 79.06batch/s, loss=1.07, acc=62.4, val_loss=1.08, val_acc=62.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 40 = 30771.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 200.29batch/s, loss=1.05, acc=62.2, val_loss=1.09, val_acc=61.4]\n",
      "Epoch 41: 100%|█████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 91.04batch/s, loss=1.09, acc=61.4, val_loss=1.07, val_acc=62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 41 = 29929.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:06<00:00, 192.51batch/s, loss=1.05, acc=62.6, val_loss=1.09, val_acc=61.4]\n",
      "Epoch 42: 100%|███████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 80.33batch/s, loss=1.09, acc=61.6, val_loss=1.08, val_acc=61.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 42 = 29929.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:07<00:00, 171.46batch/s, loss=1.05, acc=62.6, val_loss=1.09, val_acc=61.4]\n",
      "Epoch 43: 100%|████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 92.80batch/s, loss=1.09, acc=60.6, val_loss=1.1, val_acc=60.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network cost after epoch 43 = 29467.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44:  29%|██████████████████████████████▊                                                                           | 363/1250 [00:01<00:03, 228.83batch/s, loss=1.02044, acc=63.43]"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.defs.I_SuperNet import nas_loop\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "history = nas_loop(SAVE_DIR / 'nas', TRAINING_CONFIG, nas_model, criterion, train_dl, val_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed7b18a-7fa9-42c8-9513-758943e397ea",
   "metadata": {
    "id": "2ee795d5-cadb-45fe-92db-1cceb1638ffb"
   },
   "source": [
    "### Evaluating the Pruned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6c8bc-85a5-42fb-8099-d916ef2b7274",
   "metadata": {},
   "source": [
    "Let's check the test accuracy of the pruned DNN after applying PIT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625e43f-b8d0-462c-85a0-af8871fc04b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c4089ce-bfe8-4768-8456-e44d6c37b684",
    "outputId": "279110db-8205-4391-b1c6-c14bd11df777",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_metrics = icl.evaluate(nas_model, criterion, test_dl, device)\n",
    "print(f'Final model cost: {nas_model.cost}, Test Loss: {test_metrics[\"loss\"]}, Test Acc: {test_metrics[\"acc\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3344c2c-083c-4470-b594-1d69d5715fce",
   "metadata": {},
   "source": [
    "Depending on the regularization strength that you set, you should see that the cost (number of parameters) has reduced significantly once again, possibly at the cost of some accuracy degradation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569dd8b-44ce-4b5c-b1f8-3776f2c1caf5",
   "metadata": {},
   "source": [
    "### Looking at the Masks (After the Search)\n",
    "\n",
    "**Question:** Let's look again at the $\\theta$ parameters. Have they changed? How? Which layers have been pruned the most? Is there one layer that *hasn't* been pruned at all? Which one and why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4e1fa-9bc7-480b-975b-5b80aca17b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for p in nas_model.nas_parameters(): \n",
    "        print((torch.abs(p)>0.5).int().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aRJOELwKSP2",
   "metadata": {
    "id": "6aRJOELwKSP2"
   },
   "source": [
    "## Final Model Export (and Fine-Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7lXI9Y6lKfhF",
   "metadata": {
    "id": "7lXI9Y6lKfhF"
   },
   "source": [
    "As for the SuperNet, we can use the `model.export()` method to obtain a standard `nn.Module` after the optimization implemented by PIT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IfBE26P9EvzI",
   "metadata": {
    "id": "IfBE26P9EvzI"
   },
   "outputs": [],
   "source": [
    "nas_model.train_net_and_nas()\n",
    "final_model = nas_model.export()\n",
    "final_model = final_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3Ahd0um3Kxkt",
   "metadata": {
    "id": "3Ahd0um3Kxkt"
   },
   "source": [
    "Let's look at the architecture of the optimized model using `torchinfo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MhDpsvm8K0b0",
   "metadata": {
    "id": "MhDpsvm8K0b0"
   },
   "outputs": [],
   "source": [
    "print(summary(final_model, batch_shape, depth=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FuXDsNoeK650",
   "metadata": {
    "id": "FuXDsNoeK650"
   },
   "source": [
    "**Question**: Look at the exported model summary. Does the number of channels in each layer match with the mask values printed above?\n",
    "\n",
    "\n",
    "In case of the PIT algorithm, fine-tuning the exported model for some epochs is *more important* than for the SuperNet. This is because, in the same way that PIT *folds* BatchNorm layers before the search, it *unfolds* them during the export. This ensures that the final model has the same architecture of the original one.\n",
    "\n",
    "You can verify this by testing the model just after export. You will see the accuracy drop significantly. However, few epochs of fine-tuning should suffice to recover the drop, and possibly even improve the final accuracy (thanks to BatchNorm). Let's run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DVFyXZ7nLTky",
   "metadata": {
    "id": "DVFyXZ7nLTky"
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.I_SuperNet import training_loop\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "history = training_loop(SAVE_DIR / 'finetune', TRAINING_CONFIG, final_model, criterion, train_dl, val_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I3GVZA5fL2zr",
   "metadata": {
    "id": "I3GVZA5fL2zr"
   },
   "source": [
    "Finally, let's evaluate our optimized model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KyC4xItHLTk0",
   "metadata": {
    "id": "KyC4xItHLTk0"
   },
   "outputs": [],
   "source": [
    "test_metrics = icl.evaluate(final_model, criterion, test_dl, device)\n",
    "print(f'Test Loss: {test_metrics[\"loss\"]}, Test Acc: {test_metrics[\"acc\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b8eff-c48c-4c48-8f28-7af3e2cc6a69",
   "metadata": {},
   "source": [
    "**Question:** Considering SuperNet and PIT combined, by how much did you manage to compress the model size? At what cost in terms of accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adNx4j9MEJZ",
   "metadata": {
    "id": "3adNx4j9MEJZ"
   },
   "source": [
    "## Saving the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gL1dc4XgMD6X",
   "metadata": {
    "id": "gL1dc4XgMD6X"
   },
   "source": [
    "Let's save the model in a separate location to reuse it more easily in later sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-M4izO_wMDqU",
   "metadata": {
    "id": "-M4izO_wMDqU"
   },
   "outputs": [],
   "source": [
    "torch.save(final_model, SAVE_DIR / f'final_model.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
